Wang, H., Wang, G., & Zhang, H. (2024). Steering Away from Harm: An Adaptive Approach to Defending Vision Language Model Against Jailbreaks. ArXiv, [paper](abs/2411.16721).

Ghosal, S.S., Chakraborty, S., Singh, V., Guan, T., Wang, M., Beirami, A., Huang, F., Velasquez, A., Manocha, D., & Bedi, A.S. (2024). Immune: Improving Safety Against Jailbreaks in Multi-modal LLMs via Inference-Time Alignment. ArXiv, abs/2411.18688.

Li, X., Zhou, H., Wang, R., Zhou, T., Cheng, M., & Hsieh, C. (2024). MOSSBench: Is Your Multimodal Language Model Oversensitive to Safe Queries? ArXiv, abs/2406.17806.
